# YOLOv5-based-vehicle-logo-inspection-project
## 这是一个基于YOLOv5的车标识别项目，是我大三时期的“目标检测”实训提交的最终项目成果

1、项目效果<br>
<img width="519" alt="屏幕截图 2025-01-02 003841" src="https://github.com/user-attachments/assets/72b70076-fcc4-41ff-92c0-06064f931cea" /><br>
（1）运用LabelImg图像标注工具，给项目所需的数据集进行数据标签标注：① Open Dir：指定要标注的图像所在的目录；② Change Save Dir：指定标注数据保存的目录；③ Change Save Format：选定YOLO作为指定标签的保存格式。<br>
（2）使用Yolov5制作并训练自己的数据集，得到车标识别模型。<br>
（3）threading模块创建和管理线程，创建一个线程来监听键盘事件，实现了程序的并发执行。<br>
（4）实现非极大值抑制算法以去除冗余的边界框，并确定最终的检测结果。这一步骤有助于提高检测结果的准确性和可靠性。<br>
（5）使用OpenCV库在图像上绘制边界框和标签。我们可以根据检测到的车标位置和类别信息，在图像上绘制出相应大小和颜色的边界框，并在边界框旁边标注出汽车的品牌名称。<br>
2、实现步骤<br>
(1)、环境安装<br>
首先进入YOLOv5开源网址 ，手动下载zip，代码文件夹中有requirements.txt文件，里面描述了所需要的安装包。<br>
最终安装的pytorch版本为2.2.2，torchvision版本为0.17.2，python版本为3.11<br>
(2)、制作数据集<br>
① 准备数据集：<br>
收集包含各种车标的图像，并将它们分为训练集、验证集和测试集。拍摄图像应当多种角度，确保图像清晰以及数据鲁棒性。<br>
② 转换数据集格式：<br>
运用LabelImg图像标注工具，给项目所需的数据集进行数据标签标注。 <br>
<img width="1278" alt="1" src="https://github.com/user-attachments/assets/d2793b85-e6da-4813-8ff2-905441eac113" /><br>
(3)、构造YAML格式的配置文件<br>
用于指定YOLOv5模型的训练数据集和其他相关参数：<br>
① path指定了数据集的根目录；<br>
② train 指定了训练图像的路径或图像列表；<br>
③ val指定了验证图像的路径或图像列表；<br>
④ names列出了数据集中每个类别的名称及其对应的索引。<br>
<img width="562" alt="2" src="https://github.com/user-attachments/assets/d0cbb10d-1c90-4c0a-953c-8db6f722a3e6" /><br>
(4)、调整训练参数<br>
修改Yolov5的配置文件，设置适合的数据集的参数，如学习率、批次大小、训练轮数等。<br>
(5)、下载预训练模型<br>
在YOLOv5的GitHub开源网址上下载对应版本的模型，本次实训项目使用的是yolov5s.pt。<br>
![3](https://github.com/user-attachments/assets/f1d87794-9b24-4aef-8f9f-cd5b6093652d)<br>
(6)、训练及评估模型<br>
[1]：模型的训练<br>
在test.py文件中指定数据集配置文件和训练结果模型，如下：<br>
<img width="922" alt="4" src="https://github.com/user-attachments/assets/d211ef4e-1720-44fd-afd3-78839b06e477" /><br>
[2]：评估模型<br>
在验证集上评估模型的性能，查看精度、召回率等指标。评估模型好坏就是在有标注的测试集或者验证集上进行模型效果的评估，在目标检测中最常使用的评估指标为mAP。<br>
(7)、测试模型<br>
模型在没有标注的数据集上进行推理，在detect.py文件中指定测试图片和测试模型的路径：<br>
<img width="946" alt="5" src="https://github.com/user-attachments/assets/41d41335-ecfe-4446-b37a-483ab7031d75" /><br>
(8)、使用模型及功能实现<br>
通过加载模型并使用它来预测新图像的类别以及标注车标。<br>
① 通过mss库获取屏幕截图：<br>
通过np.array方法将mss对象转换成NumPy数组，以便使用OpenCV对图像进行操作。<br>
② 图像预处理：<br>
使用letterbox函数对图像进行缩放和填充，使其符合目标检测模型的输入大小（640x640）。然后去掉透明度通道，通过transpose函数将图像的通道顺序从HWC（高度、宽度、通道）转换为CHW（通道、高度、宽度），并将颜色空间从BGR转换为RGB。保证图像输入模型时的尺寸一致，并避免因图像尺寸不同导致的误差。<br>
③ 准备模型输入：<br>
将NumPy数组转换为PyTorch张量并将其发送到模型所在的设备。如果模型使用的是半精度浮点数（fp16=True），则将张量转换为半精度，否则保持为单精度。最后，将像素值归一化到[0, 1]区间。如果图像是灰度图（shape为HxW），则通过im[None]将其扩展为包含批处理维度的张量（1xHxW）。<br>
④ 对象检测推理：<br>
使用预训练的目标检测模型对图像进行推理，获得检测结果，包括边界框、置信度、类别等。<br>
通过将输入图像im传递给模型，模型执行前向传播，对图像进行对象检测，并返回检测结果。这些结果包括边界框的坐标、置信度以及对象类别等信息。由于使用了torch.no_grad()上下文管理器，因此在前向传播过程中不会计算梯度，从而节省了内存和计算资源。<br>
⑤ 实现非极大值抑制算法以去除冗余的边界框，并确定最终的检测结果：<br>
[1]使用non_max_suppression函数进行非最大值抑制（NMS），用于去除重叠度较高的冗余边界框，从而确定最终的检测结果。<br>
[2]计算边界框的交并比：对于每个边界框，计算它与其他所有边界框的交并比（IoU）。<br>
[3]抑制冗余边界框：设置一个IoU阈值；如果两个边界框的IoU超过这个阈值，则保留置信度较高的那个边界框，并抑制置信度较低的边界框。<br>
[4]重复上述步骤：重复计算IoU和抑制冗余边界框的过程，直到没有更多的边界框需要被抑制。<br>
⑥ 使用OpenCV库在图像上绘制边界框和标签：<br>
[1]cv2.rectangle()函数用于在图像上绘制矩形边界框。使用图像对象、矩形坐标、颜色和线条粗细等参数，准确标注图像中的特定区域。<br>
[2]为了标识矩形框内的内容，使用cv2.putText()函数在图像上添加文本标签。此函数接受文本内容、位置、字体、大小、颜色和线条粗细等参数，确保文本清晰可读。<br>
[3]使用cv2.imshow()函数，将处理后的图像及其标注展示给用户。该函数创建窗口并显示图像，允许用户直观地观察和验证处理效果。结合cv2.waitKey()函数来暂停程序，等待用户操作。<br>










